{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch,torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets,models,transforms\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom torch.nn import Parameter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T03:28:09.543566Z","iopub.execute_input":"2022-05-20T03:28:09.543815Z","iopub.status.idle":"2022-05-20T03:28:12.039764Z","shell.execute_reply.started":"2022-05-20T03:28:09.543789Z","shell.execute_reply":"2022-05-20T03:28:12.039074Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Read Datasets","metadata":{}},{"cell_type":"code","source":"# train.txt\ntrain_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntrain_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntrain_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n# test.txt\nval_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\nval_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\nval_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\ntest_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntest_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntest_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:14.029486Z","iopub.execute_input":"2022-05-20T03:28:14.029766Z","iopub.status.idle":"2022-05-20T03:28:14.340266Z","shell.execute_reply.started":"2022-05-20T03:28:14.029735Z","shell.execute_reply":"2022-05-20T03:28:14.339527Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# labels={0:'Normal',1:'Pneumonia',2:'COVID-19'}\ntrain_df.head()\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:16.108364Z","iopub.execute_input":"2022-05-20T03:28:16.109004Z","iopub.status.idle":"2022-05-20T03:28:16.122462Z","shell.execute_reply.started":"2022-05-20T03:28:16.108967Z","shell.execute_reply":"2022-05-20T03:28:16.121272Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/covidxct/2A_images/'  #directory path\ntrain_df['filename'] = image_path+train_df['filename']\nval_df['filename'] = image_path+val_df['filename']\ntest_df['filename'] = image_path + test_df['filename']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:17.633246Z","iopub.execute_input":"2022-05-20T03:28:17.633769Z","iopub.status.idle":"2022-05-20T03:28:17.683658Z","shell.execute_reply.started":"2022-05-20T03:28:17.633734Z","shell.execute_reply":"2022-05-20T03:28:17.682988Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"N  = train_df[train_df['label']==0]\nP = train_df[train_df['label']==1]\nC = train_df[train_df['label']==2]\nfrom sklearn.utils import resample\nN_download = resample(N, replace = True, n_samples = 25496,random_state=0)\nC_download = resample(C, replace = True, n_samples = 25496,random_state=0)\ntrain_df = pd.concat([N_download, P, C_download])\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:19.983838Z","iopub.execute_input":"2022-05-20T03:28:19.984138Z","iopub.status.idle":"2022-05-20T03:28:20.012887Z","shell.execute_reply.started":"2022-05-20T03:28:19.984106Z","shell.execute_reply":"2022-05-20T03:28:20.012193Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"N_v  = val_df[val_df['label']==0]\nP_v = val_df[val_df['label']==1]\nC_v = val_df[val_df['label']==2]\nfrom sklearn.utils import resample\nN_v_download = resample(N_v, replace = True, n_samples = 6244,random_state=0)\nP_v_download = resample(P_v, replace = True, n_samples = 6244,random_state=0)\nval_df = pd.concat([N_v_download, P_v_download, C_v])\nval_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:21.647814Z","iopub.execute_input":"2022-05-20T03:28:21.648539Z","iopub.status.idle":"2022-05-20T03:28:21.666920Z","shell.execute_reply.started":"2022-05-20T03:28:21.648502Z","shell.execute_reply":"2022-05-20T03:28:21.666300Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df = shuffle(train_df)\nval_df = shuffle(val_df)\ntest_df = shuffle(test_df)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:23.552604Z","iopub.execute_input":"2022-05-20T03:28:23.552864Z","iopub.status.idle":"2022-05-20T03:28:23.577150Z","shell.execute_reply.started":"2022-05-20T03:28:23.552837Z","shell.execute_reply":"2022-05-20T03:28:23.576444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"labels={0:'Normal',1:'Pneumonia',2:'COVID-19'}\nclass_names=['Normal','Pneumonia','COVID-19']\n\ntrain_df['label_n']=[labels[b] for b in train_df['label']]\nval_df['label_n']=[labels[b] for b in val_df['label']]\ntest_df['label_n']=[labels[b] for b in test_df['label']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:25.690551Z","iopub.execute_input":"2022-05-20T03:28:25.690800Z","iopub.status.idle":"2022-05-20T03:28:25.733527Z","shell.execute_reply.started":"2022-05-20T03:28:25.690773Z","shell.execute_reply":"2022-05-20T03:28:25.732871Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:27.863817Z","iopub.execute_input":"2022-05-20T03:28:27.864361Z","iopub.status.idle":"2022-05-20T03:28:27.885903Z","shell.execute_reply.started":"2022-05-20T03:28:27.864325Z","shell.execute_reply":"2022-05-20T03:28:27.885154Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.reset_index()\nval_df=val_df.reset_index()\ntest_df=test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:29.909174Z","iopub.execute_input":"2022-05-20T03:28:29.909559Z","iopub.status.idle":"2022-05-20T03:28:29.935439Z","shell.execute_reply.started":"2022-05-20T03:28:29.909520Z","shell.execute_reply":"2022-05-20T03:28:29.934626Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## PreProcessing Data","metadata":{}},{"cell_type":"code","source":"batch_size = 64\ninput_channel = 1\ninput_size = (224,224)\ncrop_size = (340,380)\nnum_classes=3\nnum_epochs = 20","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:31.653781Z","iopub.execute_input":"2022-05-20T03:28:31.654485Z","iopub.status.idle":"2022-05-20T03:28:31.659545Z","shell.execute_reply.started":"2022-05-20T03:28:31.654448Z","shell.execute_reply":"2022-05-20T03:28:31.658731Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):\n    def __init__(self, dataset_df, transform=None):\n        self.dataset_df = dataset_df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.dataset_df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_name = self.dataset_df['filename'][idx]\n        img = Image.open(image_name)\n        label = self.dataset_df['label'][idx]\n        \n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:33.399775Z","iopub.execute_input":"2022-05-20T03:28:33.400150Z","iopub.status.idle":"2022-05-20T03:28:33.406746Z","shell.execute_reply.started":"2022-05-20T03:28:33.400117Z","shell.execute_reply":"2022-05-20T03:28:33.405961Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"transform = {\n    'train':transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.6349431],[0.32605055])\n    ]),\n    'test':transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.63507175],[0.3278614])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:35.689893Z","iopub.execute_input":"2022-05-20T03:28:35.690433Z","iopub.status.idle":"2022-05-20T03:28:35.696781Z","shell.execute_reply.started":"2022-05-20T03:28:35.690393Z","shell.execute_reply":"2022-05-20T03:28:35.696062Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset_names=['train','val','test']\nimage_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n\ntrain_dataset = CovidDataset(train_df, transform=image_transforms['train'])\nval_dataset = CovidDataset(val_df, transform=image_transforms['val'])\ntest_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n\nimage_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n\ndataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=4) for x in dataset_names}\n\ndataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:37.836735Z","iopub.execute_input":"2022-05-20T03:28:37.837401Z","iopub.status.idle":"2022-05-20T03:28:37.847161Z","shell.execute_reply.started":"2022-05-20T03:28:37.837365Z","shell.execute_reply":"2022-05-20T03:28:37.846422Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\ndef show_tensor_img(tensor_img):\n    img=transforms.ToPILImage()(tensor_img)\n    plt.figure()\n    plt.imshow(img)\n    plt.show()\n\ndef show_img(idx):\n  show_tensor_img(train_dataset[idx][0])\nfor i in range(4):\n    show_img(i)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:42.224974Z","iopub.execute_input":"2022-05-20T03:28:42.225591Z","iopub.status.idle":"2022-05-20T03:28:43.367765Z","shell.execute_reply.started":"2022-05-20T03:28:42.225542Z","shell.execute_reply":"2022-05-20T03:28:43.366964Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Helpful Function","metadata":{}},{"cell_type":"code","source":"from collections.abc import Iterable\n\ndef set_freeze_by_idxs(model, idxs, freeze=True):\n    if not isinstance(idxs, Iterable):\n        idxs = [idxs]\n    num_child = len(list(model.children()))\n    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n    for idx, child in enumerate(model.children()):\n        if idx not in idxs:\n            continue\n        for param in child.parameters():\n            param.requires_grad = not freeze\n    return model\n            \ndef freeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, True)\n\ndef unfreeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, False)\ndef set_parameter_requires_grad(model):\n    for param in model.parameters():\n        param.requires_grad=False\n    return model\n\ndef initialize_model(model_name,num_classes,use_pretrained,unfreeze_num):\n    if model_name=='resnet50':\n        model_pre=models.wide_resnet50_2(pretrained=use_pretrained)\n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet101':\n        model_pre=models.resnet101(pretrained=use_pretrained)\n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet152':\n        model_pre=models.resnet152(pretrained=use_pretrained)\n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features \n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n\n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    else:\n        print('model not implemented')\n        return None,None\n    return model_pre, input_size","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:47.006237Z","iopub.execute_input":"2022-05-20T03:28:47.006788Z","iopub.status.idle":"2022-05-20T03:28:47.023951Z","shell.execute_reply.started":"2022-05-20T03:28:47.006737Z","shell.execute_reply":"2022-05-20T03:28:47.023014Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    cm=cm.numpy()\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        cm=cm.astype('int')\n        print('Confusion matrix, without normalization')\n#     print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '{:.2f}' if normalize else '{}'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\ndef confusion_matrix(preds, labels, conf_matrix):\n    preds = torch.argmax(preds, 1)\n    for p, t in zip(preds, labels):\n        conf_matrix[t, p] += 1\n    return conf_matrix\n\ndef calculate_all_prediction(conf_matrix):\n    total_sum = conf_matrix.sum()\n    correct_sum = (np.diag(conf_matrix)).sum()\n    prediction = round(100*float(correct_sum)/float(total_sum),2)\n    return prediction\n \ndef calculate_label_prediction(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    prediction = 0\n    if label_total_sum != 0:\n        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return prediction\n \ndef calculate_label_recall(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    recall = 0\n    if label_total_sum != 0:\n        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return recall\n \ndef calculate_f1(prediction,recall):\n    if (prediction+recall)==0:\n        return 0\n    return round(2*prediction*recall/(prediction+recall),2)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:49.984806Z","iopub.execute_input":"2022-05-20T03:28:49.985388Z","iopub.status.idle":"2022-05-20T03:28:50.000912Z","shell.execute_reply.started":"2022-05-20T03:28:49.985353Z","shell.execute_reply":"2022-05-20T03:28:50.000165Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Run and Save Model","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nmodel_all=[]\ndir='.'\ndef auto_net(model_name,num_classes,use_pretrained,unfreeze_num):\n    \n    for k in range(unfreeze_num):\n        model,input_size=initialize_model(model_name,num_classes,use_pretrained,k+1)\n        my_path=Path(dir+'/{}'.format(model_name))\n        if not my_path.is_dir(): \n            os.mkdir(my_path)\n        torch.save(model,dir+'/{}/{}_{}.pth'.format(model_name,model_name,k)) # 0 1 2 3\n        model_all.append(model)\n    return model_all\n\nmodel_name=['resnet50','resnet101','resnet152'] # 'inception_v3','resnext101'\n# for name in model_name:\n#     model_all=auto_net(name,num_classes=2,use_pretrained=True,unfreeze_num=4)\nmodel_all=auto_net(model_name[0],num_classes=3,use_pretrained=True,unfreeze_num=4)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:28:52.776197Z","iopub.execute_input":"2022-05-20T03:28:52.776720Z","iopub.status.idle":"2022-05-20T03:29:06.570005Z","shell.execute_reply.started":"2022-05-20T03:28:52.776682Z","shell.execute_reply":"2022-05-20T03:29:06.569115Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"path='./resnet50/resnet50_3.pth'\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel=torch.load(path)\nmodel=model.to(device)\n\ncriterion=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:29:13.217286Z","iopub.execute_input":"2022-05-20T03:29:13.217643Z","iopub.status.idle":"2022-05-20T03:29:16.808139Z","shell.execute_reply.started":"2022-05-20T03:29:13.217603Z","shell.execute_reply":"2022-05-20T03:29:16.807400Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train(model,epoch,num_epochs,criterion,optimizer):\n    model.train()\n    print('-' * 100)\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    running_loss = 0.0\n    running_corrects = 0\n    for idx, (inputs, labels) in enumerate(dataloaders['train']):\n        inputs,labels=inputs.to(device),labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if idx % 100 == 99:\n            print('train iteration:{},loss:{},acc:{}%'.format( idx, loss.item(),torch.sum(preds == labels.data)/batch_size*100))\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / dataset_sizes['train']\n    epoch_acc = running_corrects.double() / dataset_sizes['train']\n    print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:29:19.720376Z","iopub.execute_input":"2022-05-20T03:29:19.722483Z","iopub.status.idle":"2022-05-20T03:29:19.733671Z","shell.execute_reply.started":"2022-05-20T03:29:19.722447Z","shell.execute_reply":"2022-05-20T03:29:19.732945Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def test(model,epoch,num_epochs,criterion,optimizer,best_acc):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    best_acc=best_acc\n    best_model_wts=copy.deepcopy(model.state_dict())\n    conf_matrix = torch.zeros(num_classes, num_classes) \n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) \n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data) \n\n        #plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') \n\n    epoch_loss = running_loss / dataset_sizes['val'] \n    epoch_acc = running_corrects.double() / dataset_sizes['val']\n    print('val_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n\n    all_prediction = calculate_all_prediction(conf_matrix)\n    print('all_prediction:{}'.format(all_prediction))\n    label_prediction = [] \n    label_recall = [] \n    for i in range(num_classes):\n        label_prediction.append(calculate_label_prediction(conf_matrix,i))\n        label_recall.append(calculate_label_recall(conf_matrix,i))\n\n    keys=class_names\n    values=list(range(num_classes))\n    dictionary = dict(zip(keys, values))\n    for ei,i in enumerate(dictionary):\n        print(ei,'\\t',i,'\\t','prediction=',label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n    p = round(np.array(label_prediction).sum()/len(label_prediction),2)\n    r = round(np.array(label_recall).sum()/len(label_prediction),2) \n    print('MACRO-averaged:\\nprediction=',p,'%,recall=',r,'%,f1=',calculate_f1(p,r))\n\n    if epoch_acc > best_acc:\n        best_acc=epoch_acc.item()\n        best_model_wts=copy.deepcopy(model.state_dict())\n\n    return best_model_wts,best_acc,epoch_acc.item()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:29:23.945669Z","iopub.execute_input":"2022-05-20T03:29:23.946069Z","iopub.status.idle":"2022-05-20T03:29:23.958799Z","shell.execute_reply.started":"2022-05-20T03:29:23.946012Z","shell.execute_reply":"2022-05-20T03:29:23.957963Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Main Code","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    acc=[]\n    for epoch in range(num_epochs):\n        train(model,epoch,num_epochs,criterion,optimizer)\n        best_model_wts,best_acc,epoch_acc=test(model,epoch,num_epochs,criterion,optimizer,best_acc)\n        acc.append(epoch_acc)\n    print('*' * 100)\n    print('best_acc:{}'.format(best_acc))\n    print('*' * 100)\n    torch.save(best_model_wts, 'resnet50_3_model_best_acc.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T03:29:26.505919Z","iopub.execute_input":"2022-05-20T03:29:26.506483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Model","metadata":{}},{"cell_type":"code","source":"print(acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=range(len(acc))\ny=acc\nplt.figure()\nplt.title('densenet201_3_acc_lr=0.0001')\nplt.plot(x,y)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}